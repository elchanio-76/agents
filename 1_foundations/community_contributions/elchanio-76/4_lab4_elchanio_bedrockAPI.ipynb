{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal Project for Section 1\n",
    "\n",
    "#### Checklist\n",
    "\n",
    "1) [X] Move inference to Bedrock API & Claude/Nova.\n",
    "2) [X] Test Multilingual responses (Greek/English) - looks like Nova Lite understands Greek but responds in English.\n",
    "3) [ ] Add Google Calendar booking tool\n",
    "4) [X] Implement Bedrock guardrails (instead of evaluation) (needs testing)\n",
    "5) [ ] Create a better chat interface\n",
    "6) [X] Improve System Prompt\n",
    "7) [X] Improve tools - record contact details and questions in DynamoDB (needs testing)\n",
    "8) [X] Deploy as app (ECS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "import uuid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS Region: us-east-1 - Models:\n",
      "Model ID: stability.stable-image-remove-background-v1:0, Name: Stable Image Remove Background\n",
      "Model ID: stability.stable-image-style-guide-v1:0, Name: Stable Image Style Guide\n",
      "Model ID: stability.stable-image-control-sketch-v1:0, Name: Stable Image Control Sketch\n",
      "Model ID: anthropic.claude-sonnet-4-20250514-v1:0, Name: Claude Sonnet 4\n",
      "Model ID: stability.stable-image-erase-object-v1:0, Name: Stable Image Erase Object\n",
      "Model ID: stability.stable-image-control-structure-v1:0, Name: Stable Image Control Structure\n",
      "Model ID: stability.stable-image-search-recolor-v1:0, Name: Stable Image Search and Recolor\n",
      "Model ID: openai.gpt-oss-120b-1:0, Name: gpt-oss-120b\n",
      "Model ID: twelvelabs.pegasus-1-2-v1:0, Name: Pegasus v1.2\n",
      "Model ID: stability.stable-style-transfer-v1:0, Name: Stable Image Style Transfer\n",
      "Model ID: twelvelabs.marengo-embed-2-7-v1:0, Name: Marengo Embed v2.7\n",
      "Model ID: stability.stable-image-search-replace-v1:0, Name: Stable Image Search and Replace\n",
      "Model ID: qwen.qwen3-coder-30b-a3b-v1:0, Name: Qwen3-Coder-30B-A3B-Instruct\n",
      "Model ID: qwen.qwen3-32b-v1:0, Name: Qwen3 32B (dense)\n",
      "Model ID: stability.stable-image-inpaint-v1:0, Name: Stable Image Inpaint\n",
      "Model ID: openai.gpt-oss-20b-1:0, Name: gpt-oss-20b\n",
      "Model ID: anthropic.claude-opus-4-1-20250805-v1:0, Name: Claude Opus 4.1\n",
      "Model ID: amazon.titan-tg1-large, Name: Titan Text Large\n",
      "Model ID: amazon.titan-image-generator-v1:0, Name: Titan Image Generator G1\n",
      "Model ID: amazon.titan-image-generator-v1, Name: Titan Image Generator G1\n",
      "Model ID: amazon.titan-image-generator-v2:0, Name: Titan Image Generator G1 v2\n",
      "Model ID: amazon.nova-premier-v1:0:8k, Name: Nova Premier\n",
      "Model ID: amazon.nova-premier-v1:0:20k, Name: Nova Premier\n",
      "Model ID: amazon.nova-premier-v1:0:1000k, Name: Nova Premier\n",
      "Model ID: amazon.nova-premier-v1:0:mm, Name: Nova Premier\n",
      "Model ID: amazon.nova-premier-v1:0, Name: Nova Premier\n",
      "Model ID: amazon.titan-text-premier-v1:0, Name: Titan Text G1 - Premier\n",
      "Model ID: amazon.nova-pro-v1:0:24k, Name: Nova Pro\n",
      "Model ID: amazon.nova-pro-v1:0:300k, Name: Nova Pro\n",
      "Model ID: amazon.nova-pro-v1:0, Name: Nova Pro\n",
      "Model ID: amazon.nova-lite-v1:0:24k, Name: Nova Lite\n",
      "Model ID: amazon.nova-lite-v1:0:300k, Name: Nova Lite\n",
      "Model ID: amazon.nova-lite-v1:0, Name: Nova Lite\n",
      "Model ID: amazon.nova-canvas-v1:0, Name: Nova Canvas\n",
      "Model ID: amazon.nova-reel-v1:0, Name: Nova Reel\n",
      "Model ID: amazon.nova-reel-v1:1, Name: Nova Reel\n",
      "Model ID: amazon.nova-micro-v1:0:24k, Name: Nova Micro\n",
      "Model ID: amazon.nova-micro-v1:0:128k, Name: Nova Micro\n",
      "Model ID: amazon.nova-micro-v1:0, Name: Nova Micro\n",
      "Model ID: amazon.nova-sonic-v1:0, Name: Nova Sonic\n",
      "Model ID: amazon.titan-embed-g1-text-02, Name: Titan Text Embeddings v2\n",
      "Model ID: amazon.titan-text-lite-v1:0:4k, Name: Titan Text G1 - Lite\n",
      "Model ID: amazon.titan-text-lite-v1, Name: Titan Text G1 - Lite\n",
      "Model ID: amazon.titan-text-express-v1:0:8k, Name: Titan Text G1 - Express\n",
      "Model ID: amazon.titan-text-express-v1, Name: Titan Text G1 - Express\n",
      "Model ID: amazon.titan-embed-text-v1:2:8k, Name: Titan Embeddings G1 - Text\n",
      "Model ID: amazon.titan-embed-text-v1, Name: Titan Embeddings G1 - Text\n",
      "Model ID: amazon.titan-embed-text-v2:0:8k, Name: Titan Text Embeddings V2\n",
      "Model ID: amazon.titan-embed-text-v2:0, Name: Titan Text Embeddings V2\n",
      "Model ID: amazon.titan-embed-image-v1:0, Name: Titan Multimodal Embeddings G1\n",
      "Model ID: amazon.titan-embed-image-v1, Name: Titan Multimodal Embeddings G1\n",
      "Model ID: stability.stable-diffusion-xl-v1:0, Name: SDXL 1.0\n",
      "Model ID: stability.stable-diffusion-xl-v1, Name: SDXL 1.0\n",
      "Model ID: ai21.jamba-1-5-large-v1:0, Name: Jamba 1.5 Large\n",
      "Model ID: ai21.jamba-1-5-mini-v1:0, Name: Jamba 1.5 Mini\n",
      "Model ID: anthropic.claude-instant-v1:2:100k, Name: Claude Instant\n",
      "Model ID: anthropic.claude-v2:0:18k, Name: Claude\n",
      "Model ID: anthropic.claude-v2:0:100k, Name: Claude\n",
      "Model ID: anthropic.claude-v2:1:18k, Name: Claude\n",
      "Model ID: anthropic.claude-v2:1:200k, Name: Claude\n",
      "Model ID: anthropic.claude-3-sonnet-20240229-v1:0:28k, Name: Claude 3 Sonnet\n",
      "Model ID: anthropic.claude-3-sonnet-20240229-v1:0:200k, Name: Claude 3 Sonnet\n",
      "Model ID: anthropic.claude-3-sonnet-20240229-v1:0, Name: Claude 3 Sonnet\n",
      "Model ID: anthropic.claude-3-haiku-20240307-v1:0:48k, Name: Claude 3 Haiku\n",
      "Model ID: anthropic.claude-3-haiku-20240307-v1:0:200k, Name: Claude 3 Haiku\n",
      "Model ID: anthropic.claude-3-haiku-20240307-v1:0, Name: Claude 3 Haiku\n",
      "Model ID: anthropic.claude-3-opus-20240229-v1:0:12k, Name: Claude 3 Opus\n",
      "Model ID: anthropic.claude-3-opus-20240229-v1:0:28k, Name: Claude 3 Opus\n",
      "Model ID: anthropic.claude-3-opus-20240229-v1:0:200k, Name: Claude 3 Opus\n",
      "Model ID: anthropic.claude-3-opus-20240229-v1:0, Name: Claude 3 Opus\n",
      "Model ID: anthropic.claude-3-5-sonnet-20240620-v1:0, Name: Claude 3.5 Sonnet\n",
      "Model ID: anthropic.claude-3-5-sonnet-20241022-v2:0, Name: Claude 3.5 Sonnet v2\n",
      "Model ID: anthropic.claude-3-7-sonnet-20250219-v1:0, Name: Claude 3.7 Sonnet\n",
      "Model ID: anthropic.claude-3-5-haiku-20241022-v1:0, Name: Claude 3.5 Haiku\n",
      "Model ID: anthropic.claude-opus-4-20250514-v1:0, Name: Claude Opus 4\n",
      "Model ID: cohere.command-r-v1:0, Name: Command R\n",
      "Model ID: cohere.command-r-plus-v1:0, Name: Command R+\n",
      "Model ID: cohere.embed-english-v3:0:512, Name: Embed English\n",
      "Model ID: cohere.embed-english-v3, Name: Embed English\n",
      "Model ID: cohere.embed-multilingual-v3:0:512, Name: Embed Multilingual\n",
      "Model ID: cohere.embed-multilingual-v3, Name: Embed Multilingual\n",
      "Model ID: deepseek.r1-v1:0, Name: DeepSeek-R1\n",
      "Model ID: meta.llama3-8b-instruct-v1:0, Name: Llama 3 8B Instruct\n",
      "Model ID: meta.llama3-70b-instruct-v1:0, Name: Llama 3 70B Instruct\n",
      "Model ID: meta.llama3-1-8b-instruct-v1:0, Name: Llama 3.1 8B Instruct\n",
      "Model ID: meta.llama3-1-70b-instruct-v1:0, Name: Llama 3.1 70B Instruct\n",
      "Model ID: meta.llama3-2-11b-instruct-v1:0, Name: Llama 3.2 11B Instruct\n",
      "Model ID: meta.llama3-2-90b-instruct-v1:0, Name: Llama 3.2 90B Instruct\n",
      "Model ID: meta.llama3-2-1b-instruct-v1:0, Name: Llama 3.2 1B Instruct\n",
      "Model ID: meta.llama3-2-3b-instruct-v1:0, Name: Llama 3.2 3B Instruct\n",
      "Model ID: meta.llama3-3-70b-instruct-v1:0, Name: Llama 3.3 70B Instruct\n",
      "Model ID: meta.llama4-scout-17b-instruct-v1:0, Name: Llama 4 Scout 17B Instruct\n",
      "Model ID: meta.llama4-maverick-17b-instruct-v1:0, Name: Llama 4 Maverick 17B Instruct\n",
      "Model ID: mistral.mistral-7b-instruct-v0:2, Name: Mistral 7B Instruct\n",
      "Model ID: mistral.mixtral-8x7b-instruct-v0:1, Name: Mixtral 8x7B Instruct\n",
      "Model ID: mistral.mistral-large-2402-v1:0, Name: Mistral Large (24.02)\n",
      "Model ID: mistral.mistral-small-2402-v1:0, Name: Mistral Small (24.02)\n",
      "Model ID: mistral.pixtral-large-2502-v1:0, Name: Pixtral Large (25.02)\n"
     ]
    }
   ],
   "source": [
    "# The usual start\n",
    "os.environ['AWS_BEARER_TOKEN_BEDROCK'] = os.getenv('AWS_BEARER_TOKEN_BEDROCK', 'your-key-if-not-using-env')\n",
    "\n",
    "region = 'us-east-1' # change to your preferred region - be aware that not all regions have access to all models. If in doubt, use us-east-1.\n",
    "\n",
    "bedrock = boto3.client(service_name=\"bedrock\", region_name=region) # use this for information and management calls (such as model listings)\n",
    "bedrock_runtime = boto3.client(service_name=\"bedrock-runtime\", region_name=region) # this is for inference.\n",
    "\n",
    "# Let's do a quick test to see if works.\n",
    "# We will list the available models.\n",
    "\n",
    "response = bedrock.list_foundation_models()\n",
    "models = response['modelSummaries']\n",
    "print(f'AWS Region: {region} - Models:')\n",
    "for model in models:\n",
    "    print(f\"Model ID: {model['modelId']}, Name: {model['modelName']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushover user found and starts with u\n",
      "Pushover token found and starts with a\n"
     ]
    }
   ],
   "source": [
    "# For pushover\n",
    "\n",
    "pushover_user = os.getenv(\"PUSHOVER_USER\")\n",
    "pushover_token = os.getenv(\"PUSHOVER_TOKEN\")\n",
    "pushover_url = \"https://api.pushover.net/1/messages.json\"\n",
    "\n",
    "if pushover_user:\n",
    "    print(f\"Pushover user found and starts with {pushover_user[0]}\")\n",
    "else:\n",
    "    print(\"Pushover user not found\")\n",
    "\n",
    "if pushover_token:\n",
    "    print(f\"Pushover token found and starts with {pushover_token[0]}\")\n",
    "else:\n",
    "    print(\"Pushover token not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DynamoDB client\n",
    "dynamodb = boto3.resource('dynamodb', \n",
    "                          region_name='us-east-1', \n",
    "                          aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'),\n",
    "                          aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    ")\n",
    "table = dynamodb.Table('user-contacts')  # Replace with your table name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push(message):\n",
    "    print(f\"Push: {message}\")\n",
    "    payload = {\"user\": pushover_user, \"token\": pushover_token, \"message\": message}\n",
    "    requests.post(pushover_url, data=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Push: HEY!!\n"
     ]
    }
   ],
   "source": [
    "push(\"HEY!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_user_details(email, name=\"Name not provided\", notes=\"not provided\"):\n",
    "    try:\n",
    "        # Record in DynamoDB\n",
    "        item = {\n",
    "            'id': str(uuid.uuid4()),\n",
    "            'email': email,\n",
    "            'name': name,\n",
    "            'notes': notes,\n",
    "            'timestamp': datetime.utcnow().isoformat(),\n",
    "            'source': 'website-chat'\n",
    "        }\n",
    "        \n",
    "        table.put_item(Item=item)\n",
    "        \n",
    "        # Keep the push notification\n",
    "        push(f\"Recording interest from {name} with email {email} and notes {notes}\")\n",
    "        \n",
    "        return {\"recorded\": \"ok\", \"id\": item['id']}\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Fallback to just notification if DynamoDB fails\n",
    "        push(f\"Recording interest from {name} with email {email} and notes {notes}\")\n",
    "        return {\"recorded\": \"notification_only\", \"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_unknown_question(question):\n",
    "    push(f\"Recording {question} asked that I couldn't answer\")\n",
    "    return {\"recorded\": \"ok\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_user_details_json = {\n",
    "    \"name\": \"record_user_details\",\n",
    "    \"description\": \"Use this tool to record that a user is interested in being in touch and provided an email address\",\n",
    "    \"inputSchema\": {\n",
    "        \"json\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"email\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The email address of this user\"\n",
    "                },\n",
    "                \"name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The user's name, if they provided it\"\n",
    "                }\n",
    "                ,\n",
    "                \"notes\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Any additional information about the conversation that's worth recording to give context\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"email\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_unknown_question_json = {\n",
    "    \"name\": \"record_unknown_question\",\n",
    "    \"description\": \"Always use this tool to record any question that couldn't be answered as you didn't know the answer\",\n",
    "    \"inputSchema\": { \n",
    "        \"json\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"question\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The question that couldn't be answered\"\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"question\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = {\n",
    "        \"tools\": \n",
    "            [{\"toolSpec\": record_user_details_json},\n",
    "            {\"toolSpec\": record_unknown_question_json}\n",
    "            ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tools': [{'toolSpec': {'name': 'record_user_details',\n",
       "    'description': 'Use this tool to record that a user is interested in being in touch and provided an email address',\n",
       "    'inputSchema': {'json': {'type': 'object',\n",
       "      'properties': {'email': {'type': 'string',\n",
       "        'description': 'The email address of this user'},\n",
       "       'name': {'type': 'string',\n",
       "        'description': \"The user's name, if they provided it\"},\n",
       "       'notes': {'type': 'string',\n",
       "        'description': \"Any additional information about the conversation that's worth recording to give context\"}},\n",
       "      'required': ['email'],\n",
       "      'additionalProperties': False}}}},\n",
       "  {'toolSpec': {'name': 'record_unknown_question',\n",
       "    'description': \"Always use this tool to record any question that couldn't be answered as you didn't know the answer\",\n",
       "    'inputSchema': {'json': {'type': 'object',\n",
       "      'properties': {'question': {'type': 'string',\n",
       "        'description': \"The question that couldn't be answered\"}},\n",
       "      'required': ['question'],\n",
       "      'additionalProperties': False}}}}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function can take a list of tool calls, and run them. This is the IF statement!!\n",
    "\n",
    "# def handle_tool_calls(tool_calls):\n",
    "#    results = []\n",
    "#    for tool_call in tool_calls:\n",
    "#        tool_name = tool_call.function.name\n",
    "#        arguments = json.loads(tool_call.function.arguments)\n",
    "#        print(f\"Tool called: {tool_name}\", flush=True)\n",
    "#\n",
    "#       # THE BIG IF STATEMENT!!!\n",
    "#\n",
    "#        if tool_name == \"record_user_details\":\n",
    "#            result = record_user_details(**arguments)\n",
    "#        elif tool_name == \"record_unknown_question\":\n",
    "#            result = record_unknown_question(**arguments)\n",
    "#\n",
    "#        results.append({\"role\": \"tool\",\"content\": json.dumps(result),\"tool_call_id\": tool_call.id})\n",
    "#   return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Push: Recording this is a really hard question asked that I couldn't answer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'recorded': 'ok'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()[\"record_unknown_question\"](\"this is a really hard question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text\n",
    "\n",
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()\n",
    "\n",
    "name = \"Eleftherios Chaniotakis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add today's date to the system prompt (reduces chances of LLM responding that we're in the future)\n",
    "\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "system_prompt = f\"\"\"Today's date is {today}.\n",
    "\n",
    "You are {name}'s professional AI representative on their website.\n",
    "\n",
    "## Your Role:\n",
    "- Answer questions about {name}'s career, skills, experience, and professional background\n",
    "- Maintain a professional, engaging tone suitable for potential clients and employers\n",
    "- Stay strictly within professional topics - redirect personal or off-topic questions\n",
    "\n",
    "## Key Behaviors:\n",
    "1. **Professional Focus**: Only discuss career-related topics, technical skills, work experience, and professional achievements\n",
    "2. **Lead Generation**: When users show interest, guide them toward providing contact information\n",
    "3. **Knowledge Gaps**: Use the record_unknown_question tool for ANY question you cannot answer\n",
    "4. **Contact Collection**: Use record_user_details tool when users provide email addresses\n",
    "\n",
    "## Response Guidelines:\n",
    "- Keep responses concise and relevant\n",
    "- Highlight {name}'s key strengths and expertise\n",
    "- Ask follow-up questions to understand visitor needs\n",
    "- Suggest next steps (portfolio review, consultation, etc.)\n",
    "\n",
    "## Available Information:\n",
    "### Summary:\n",
    "{summary}\n",
    "\n",
    "### LinkedIn Profile:\n",
    "{linkedin}\n",
    "\n",
    "Represent {name} authentically and professionally. Focus on their value proposition and encourage meaningful professional connections.\"\"\"\n",
    "\n",
    "system_prompt = [{\"text\": system_prompt}]\n",
    "\n",
    "BEDROCK_MODEL_ID = 'us.amazon.nova-pro-v1:0'  # try \"us.amazon.nova-lite-v1:0\" for faster responses.\n",
    "messages=[]\n",
    "\n",
    "# Amazon Bedrock Guardrails configuration\n",
    "# First create a guardrail in AWS Console\n",
    "# Then configure a policy. Choose:\n",
    "# - Hate & Toxicity: Enable with HIGH blocking strength\n",
    "# - Denied topics: Add \"Politics\", \"Personal opinions\", \"Controversial topics\"\n",
    "# then replace the guardrail ID with the actual guardrail identifier.\n",
    "\n",
    "guardrails_config = {\n",
    "    \"guardrailIdentifier\": \"your-guardrail-id\",  # Replace with your guardrail ID\n",
    "    \"guardrailVersion\": \"DRAFT\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_openai_to_bedrock(history):\n",
    "    \"\"\"Convert OpenAI chat format to Bedrock Converse API format\"\"\"\n",
    "    bedrock_messages = []\n",
    "    \n",
    "    for message in history:\n",
    "        if message[\"role\"] == \"system\":\n",
    "            continue  # Handle system messages separately\n",
    "        elif message[\"role\"] in [\"user\", \"assistant\"]:\n",
    "            bedrock_messages.append({\n",
    "                \"role\": message[\"role\"],\n",
    "                \"content\": [{\"text\": message[\"content\"]}]\n",
    "            })\n",
    "    \n",
    "    return bedrock_messages\n",
    "\n",
    "def handle_tool_calls(tool_call):\n",
    "    \"\"\"Handle single Bedrock tool call\"\"\"\n",
    "    tool_name = tool_call['name']\n",
    "    arguments = tool_call['input']  # Already a dict in Bedrock\n",
    "    print(f\"Tool called: {tool_name} with arguments {arguments}\", flush=True)\n",
    "    \n",
    "    tool = globals().get(tool_name)\n",
    "    result = tool(**arguments) if tool else {}\n",
    "    \n",
    "    return {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\n",
    "            \"toolResult\": {\n",
    "                \"toolUseId\": tool_call['toolUseId'],\n",
    "                \"content\": [{\"json\": result}]\n",
    "            }\n",
    "        }]\n",
    "    }\n",
    "\n",
    "def chat(message, history):\n",
    "    # Convert history to Bedrock format\n",
    "    messages = convert_openai_to_bedrock(history)\n",
    "    \n",
    "    # Add current message\n",
    "    messages.append({\n",
    "        \"role\": \"user\", \n",
    "        \"content\": [{\"text\": message}]\n",
    "    })\n",
    "    \n",
    "    done = False\n",
    "    while not done:\n",
    "        response = bedrock_runtime.converse(\n",
    "            modelId=BEDROCK_MODEL_ID, \n",
    "            messages=messages, \n",
    "            system=system_prompt,\n",
    "            toolConfig=tools,\n",
    "            guardrailConfig=guardrails_config  # Add guardrails\n",
    "        )\n",
    "\n",
    "        # Check for guardrail intervention\n",
    "        if 'trace' in response and 'guardrail' in response['trace']:\n",
    "            guardrail_trace = response['trace']['guardrail']\n",
    "            if guardrail_trace.get('action') == 'GUARDRAIL_INTERVENED':\n",
    "                return \"I can only discuss professional topics related to my career and experience. Please ask about my work, skills, or professional background.\"\n",
    "\n",
    "        output_message = response['output']['message']\n",
    "        messages.append(output_message)\n",
    "        finish_reason = response['stopReason']\n",
    "        \n",
    "        if finish_reason == \"tool_use\":\n",
    "            tool_requests = output_message['content']\n",
    "            for tool_request in tool_requests:\n",
    "                if 'toolUse' in tool_request:\n",
    "                    tool_result = handle_tool_calls(tool_request['toolUse'])\n",
    "                    messages.append(tool_result)\n",
    "        else:\n",
    "            done = True\n",
    "    \n",
    "    return output_message['content'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool called: record_user_details with arguments {'email': 'user@example.com'}\n",
      "Push: Recording interest from Name not provided with email user@example.com and notes not provided\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now for deployment\n",
    "\n",
    "This code is in `app.py`\n",
    "\n",
    "We will deploy to HuggingFace Spaces.\n",
    "\n",
    "Before you start: remember to update the files in the \"me\" directory - your LinkedIn profile and summary.txt - so that it talks about you! Also change `self.name = \"Ed Donner\"` in `app.py`..  \n",
    "\n",
    "Also check that there's no README file within the 1_foundations directory. If there is one, please delete it. The deploy process creates a new README file in this directory for you.\n",
    "\n",
    "1. Visit https://huggingface.co and set up an account  \n",
    "2. From the Avatar menu on the top right, choose Access Tokens. Choose \"Create New Token\". Give it WRITE permissions - it needs to have WRITE permissions! Keep a record of your new key.  \n",
    "3. In the Terminal, run: `uv tool install 'huggingface_hub[cli]'` to install the HuggingFace tool, then `hf auth login` to login at the command line with your key. Afterwards, run `hf auth whoami` to check you're logged in  \n",
    "4. Take your new token and add it to your .env file: `HF_TOKEN=hf_xxx` for the future\n",
    "5. From the 1_foundations folder, enter: `uv run gradio deploy` \n",
    "6. Follow its instructions: name it \"career_conversation\", specify app.py, choose cpu-basic as the hardware, say Yes to needing to supply secrets, provide your openai api key, your pushover user and token, and say \"no\" to github actions.  \n",
    "\n",
    "Thank you Robert, James, Martins, Andras and Priya for these tips.  \n",
    "Please read the next 2 sections - how to change your Secrets, and how to redeploy your Space (you may need to delete the README.md that gets created in this 1_foundations directory).\n",
    "\n",
    "#### More about these secrets:\n",
    "\n",
    "If you're confused by what's going on with these secrets: it just wants you to enter the key name and value for each of your secrets -- so you would enter:  \n",
    "`OPENAI_API_KEY`  \n",
    "Followed by:  \n",
    "`sk-proj-...`  \n",
    "\n",
    "And if you don't want to set secrets this way, or something goes wrong with it, it's no problem - you can change your secrets later:  \n",
    "1. Log in to HuggingFace website  \n",
    "2. Go to your profile screen via the Avatar menu on the top right  \n",
    "3. Select the Space you deployed  \n",
    "4. Click on the Settings wheel on the top right  \n",
    "5. You can scroll down to change your secrets (Variables and Secrets section), delete the space, etc.\n",
    "\n",
    "#### And now you should be deployed!\n",
    "\n",
    "If you want to completely replace everything and start again with your keys, you may need to delete the README.md that got created in this 1_foundations folder.\n",
    "\n",
    "Here is mine: https://huggingface.co/spaces/ed-donner/Career_Conversation\n",
    "\n",
    "I just got a push notification that a student asked me how they can become President of their country ðŸ˜‚ðŸ˜‚\n",
    "\n",
    "For more information on deployment:\n",
    "\n",
    "https://www.gradio.app/guides/sharing-your-app#hosting-on-hf-spaces\n",
    "\n",
    "To delete your Space in the future:  \n",
    "1. Log in to HuggingFace\n",
    "2. From the Avatar menu, select your profile\n",
    "3. Click on the Space itself and select the settings wheel on the top right\n",
    "4. Scroll to the Delete section at the bottom\n",
    "5. ALSO: delete the README file that Gradio may have created inside this 1_foundations folder (otherwise it won't ask you the questions the next time you do a gradio deploy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">â€¢ First and foremost, deploy this for yourself! It's a real, valuable tool - the future resume..<br/>\n",
    "            â€¢ Next, improve the resources - add better context about yourself. If you know RAG, then add a knowledge base about you.<br/>\n",
    "            â€¢Â Add in more tools! You could have a SQL database with common Q&A that the LLM could read and write from?<br/>\n",
    "            â€¢ Bring in the Evaluator from the last lab, and add other Agentic patterns.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">Aside from the obvious (your career alter-ego) this has business applications in any situation where you need an AI assistant with domain expertise and an ability to interact with the real world.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
